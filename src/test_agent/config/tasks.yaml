exploration_task:
  description: >
    Use Playwright MCP to deeply explore the {application_url} based on the test description "{test_description}".
    Identify all key UI elements, navigation flows, forms, roles, selectors, and validations that are necessary to write the test script for the given test description "{test_description}".
    and produce complete structured UI and workflow data. Note these will be used by downstream agents.
    Return ONLY the structured exploration JSON output with the elements and each element must have:
      - "role": ARIA role if available
      - "label": visible label or text if available
      - "selector": best selector (prefer role-based selectors like getByRole, getByLabel, getByTestId)
      - "type": element type (e.g., button, input, link)
      - "actions": possible actions (e.g., click, fill)
      - "validations": any validations or constraints (e.g., required, pattern)
      - "navigation": any navigation flows or links to other pages
    Do NOT wrap the output in triple backticks or any code fences.
    Do NOT add any explanations, comments, or markdown formatting.
  expected_output: >
    A pretty-printed JSON array of elements, each with "role", "label", "selector", "type", "actions", "validations", and "navigation" fields.
  agent: app_explorer
  output_file: ./output/exploration_data.json

strip_exploration_backticks_task:
  description: >
    Strip triple backticks and the extra text such as any explanation and JSON at the start also if there is any explanation at the end from ./output/exploration_data.json using StripTripleBackticksTool.
  agent: post_processing_agent
  tool: StripTripleBackticksTool
  params:
    filename: ./output/exploration_data.json
  expected_output: >
    The same file, with all triple backticks removed.

test_case_writing_task:
  description: >
    You are a test case writing agent.
    Consume the exploration data produced by the 'app_explorer' agent.
    Use this data plus the "{test_description}" to write detailed, well-structured test cases in JSON format.
    Find the Primary functionality that is being tested based on its title "{test_name}".
    Write test cases only for the primary functionality by obtaining details from "{test_description}".
    output a DRAFT TEST PLAN as JSON with an array "scenarios". Each scenario must have:
      - "id": short machine-safe id (kebab-case)
      - "title": a clear title
      - "preconditions": preconditions or setup
      - "steps": test steps
      - "expected_results": expected results
      - "priority": one of ["High","Medium","Low"]
      - "kind": "positive" or "negative"
    Provide as many relevant test cases as possible.
    Return ONLY a JSON array of test cases and nothing else.
    Do NOT wrap the output in triple backticks or any code fences.
    Do NOT add any explanations, comments, or markdown formatting.
    Only return the test cases in the specified JSON format.
  expected_output: >
   A pretty-printed JSON array of test cases, each with "title", "preconditions", "steps", and "expected_results" fields.
  agent: test_case_writer
  context:
    - exploration_task
  output_file: ./output/Testcases/{test_name}_test_cases.json

strip_testcases_backticks_task:
  description: >
    Strip triple backticks and the extra text such as any explanation and JSON at the start also if there is any explanation at the end from ./output/Testcases/{test_name}_test_cases.json using StripTripleBackticksTool.
  agent: post_processing_agent
  tool: StripTripleBackticksTool
  params:
    filename: ./output/Testcases/{test_name}_test_cases.json
  expected_output: >
    The same file, with all triple backticks removed.

script_generation_task:
  description: >
    You are an expert Playwright test generator agent.
    Your mission is to generate robust, fully working Playwright test scripts in TypeScript for the specified {application_url} based on "{test_description}" and "{test_name}".
    Mandatory instructions:
    1.Before writing any code, you MUST thoroughly explore the data produced by the 'app_explorer' agent and identify interactive elements and selectors.
    2.Carefully read the test cases generated by the test_case writer, and enumerate every single test case and its user action, input, and assertion described.
        **Do not omit, paraphrase, or summarize steps; every described action must appear as code.**
    5.All selectors in the script MUST come from the exploration data produced by the app_explorer agent.
    **When generating tests in TypeScript, use only Playwright’s recommended role-based locators such as getByRole(), getByLabel(), getByTestId().**
    6. If any selector is missing, you MUST explore the application using Playwright MCP to find the missing selectors. don't guess selectors.
    **When generating tests in TypeScript, use only Playwright’s recommended role-based locators such as getByRole(), getByLabel(), getByTestId().**
    7. If any step or validation is unclear or ambiguous, you MUST explore the application
    **When generating tests in TypeScript, use only Playwright’s recommended role-based locators such as getByRole(), getByLabel(), getByTestId().**
    8.Use Playwright’s test hooks to optimize test execution, except when the main functionality being tested is the login process itself:
      - If the test is not for login functionality, log in once using a beforeEach block.
      - If the test is for login functionality, include the login steps directly within the test case, and do not use a beforeEach login
      - Also Use beforeEach to navigate to the initial page or feature area for each test, as appropriate.
      - Optionally use `afterAll` or `afterEach` to clean up if needed.
    9.Structure tests with clear, descriptive names indicating the feature and scenario.
    10.Ensure each test is independent and repeatable without relying on others.
    **Do NOT wrap the code in triple backticks or any code fences.**
    **Do NOT add any explanations, comments, or markdown formatting.**
    **Do not reference or include input URLs as JSON.**
    **Return ONLY the corrected, fully runnable TypeScript code.**
 
    Example output:
    import { test, expect } from '@playwright/test';
    test('Scenario name', async ({ page }) => {
    // All concrete steps described in the test description, matching its detail
    });
  expected_output: >
    Only the raw, runnable TypeScript Playwright script code, beginning with import { test, expect } from '@playwright/test'; and ending with a closing bracket—no markdown, code fences, commentary, headings, or extra text.
  agent: script_generator
  context:
    - exploration_task
    - test_case_writing_task
  output_file: ./tests/{test_name}.spec.ts

strip_testscript_backticks_task:
  description: >
    Strip triple backticks and the extra text such as any explanation and typescript at the start also if there is any explanation at the end from ./tests/{test_name}.spec.ts using StripTripleBackticksTool.
  agent: post_processing_agent
  tool: StripTripleBackticksTool
  params:
    filename: ./tests/{test_name}.spec.ts
  expected_output: >
    The same file, with all triple backticks removed.


test_execution_and_fix_task:
  description: >
    Run the Playwright script named {test_name}.spec.ts against {application_url} using playwright.
    If script is passed return the script as it is.
    If the test script fails, collect error and artifacts, understand the error and if needed use Playwright MCP to explore the application and attempt up to 3 repairs,
    overwriting the script each time with the fixed version by following below rules:
    1. Carefully analyze the error and screenshot analysis (if available)
    2. Fix only what is necessary to make the test pass
    3. **Do NOT add any explanations, comments, or markdown formatting.**
    4. **Do NOT wrap the code in triple backticks or any code fences.**
    5. **Return ONLY the corrected, fully runnable TypeScript code.**
    6. **Do not reference or include input URLs as JSON.**
    7. **When generating tests in TypeScript, use only Playwright’s recommended role-based locators such as getByRole(), getByLabel(), getByTestId().**

    Track all fixes and script versions.
    At the end, generate a markdown report that includes:
      - The original script from Agent 1
      - Each fix attempt: summary, code, errors, artifacts
      - The final script after last fix
      - Pass/fail result
  expected_output: >
    Markdown report matching the required format (# Test Automation Report) saved to output/final_report.md
    CRITICAL: Do NOT just reference saving a report. Output the COMPLETE markdown report content.The report must contain all sections with actual content
  agent: test_executor
  context:
    - script_generation_task
  output_file: ./output/final_report.md
  markdown: true
  max_retries: 1
